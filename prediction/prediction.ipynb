{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accommodation Price Prediction - Modelling and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Number of Beds</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price (HKD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Kita</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Taito</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hotel Room</td>\n",
       "      <td>621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Shinagawa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Sumida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Taito</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hotel Room</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source   Location  Number of Beds        Type  Price (HKD)\n",
       "0  Hotel       Kita             NaN   Apartment        589.0\n",
       "1  Hotel      Taito             2.0  Hotel Room        621.0\n",
       "2  Hotel  Shinagawa             NaN   Apartment       1807.0\n",
       "3  Hotel     Sumida             NaN   Apartment        811.0\n",
       "4  Hotel      Taito             1.0  Hotel Room        378.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../cleaning/accommodation.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source             object\n",
       "Location           object\n",
       "Number of Beds    float64\n",
       "Type               object\n",
       "Price (HKD)       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source             0\n",
       "Location           0\n",
       "Number of Beds    75\n",
       "Type               0\n",
       "Price (HKD)        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating input from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns='Price (HKD)')\n",
    "y_train = df['Price (HKD)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating pipeline for the transformation of different features.\n",
    "\n",
    "- A one-hot encoding scheme is applied to transform categorical variables.\n",
    "- Missing numerical data is imputer using the mdian of the variable, and all numerical data are scaled using a standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "cat_var = ['Source', 'Location', 'Type']\n",
    "\n",
    "var_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('oh_encoder', OneHotEncoder(), cat_var),\n",
    "    ('imputer', var_pipeline, ['Number of Beds'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building and model comparison\n",
    "\n",
    "Four candidate models are chosen to be the regressors that predict the accommodation prices.\n",
    "\n",
    "1. Linear Regression\n",
    "- Linear regression is a regression model that assumes linear relationship between feaures and the target. A potential problem of linear regression is that it might overfit the data since it assumes equal importance of all the features. Therefore, the linear regression model is included for baseline comparison.\n",
    "\n",
    "2. Elastic Net Regression\n",
    "- Elastic Net Regression is a regression model of which the loss function includes both L1 (Lasso) and L2 (Ridge) regularizers. Therefore it has the characteristics of both regularization methods and it generally outperforms the two. The lambda hyperparameter controls the model complexity while alpha controls the ratio between the L1 and L2 regularizers.\n",
    "\n",
    "3. Support Vector Regression\n",
    "- Support vector regression model uses the same principle as a support vector machine. Instead of maximizing the margins, it minimizes the margin by finding a best-fit hyperplane.\n",
    "\n",
    "4. Gradient Boosting Regression\n",
    "- Gradient Boosting regression is an ensemble method that sequentially trains decision trees which are then aggregated for prediction. The trees are trained on the pervious residual value, which is the difference between the previous predicted value and the target value.\n",
    "\n",
    "\n",
    "Dummy regression is included for baseline comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "mean score: 693.4471280026223\n",
      "standard deviation: 239.7945611524849\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar Wong\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:607: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 616418618.4368035, tolerance: 126794.96467776927\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regression\n",
      "mean score: 581.3024021492453\n",
      "standard deviation: 63.00992918736599\n",
      "\n",
      "\n",
      "Support Vector Regression\n",
      "mean score: 486.1645620481542\n",
      "standard deviation: 52.718640723201204\n",
      "\n",
      "\n",
      "Gradient Boosting Regression\n",
      "mean score: 514.4460624479647\n",
      "standard deviation: 124.52159241982432\n",
      "\n",
      "\n",
      "Dummy Regression\n",
      "mean score: 583.0653510255576\n",
      "standard deviation: 66.51153879895924\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "# Create a dictionary of regressors\n",
    "regressors = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Elastic Net Regression': ElasticNet(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Gradient Boosting Regression': GradientBoostingRegressor(),\n",
    "    'Dummy Regression': DummyRegressor()\n",
    "}\n",
    "\n",
    "# Create hyperparameter grids\n",
    "grids = {\n",
    "    'Linear Regression': {\n",
    "\n",
    "    },\n",
    "    'Elastic Net Regression':{\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "        'l1_ratio': [0, 0.2, 0.5, 0.8, 1]\n",
    "    },\n",
    "    'Support Vector Regression':{\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': [0.001, 0.1, 1, 5, 10],\n",
    "        'C': [0.1, 1, 5, 10, 50]\n",
    "    },\n",
    "    'Gradient Boosting Regression':{\n",
    "        'learning_rate': [0.1, 0.2, 0.5, 1],\n",
    "        'n_estimators': [50, 80, 100, 150],\n",
    "        'loss': ['squared_error', 'huber'],\n",
    "        'alpha': [0.1, 0.5, 0.9]\n",
    "    },\n",
    "    'Dummy Regression':{\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "for name, regressor in regressors.items():\n",
    "    reg_cv = GridSearchCV(regressor, grids[name], scoring='neg_mean_absolute_error', cv=3, n_jobs=-1)\n",
    "    reg_cv.fit(X_train_prepared, y_train)\n",
    "    print(name)\n",
    "    print(f'mean score: {-reg_cv.best_score_}')\n",
    "    std = reg_cv.cv_results_['std_test_score'][reg_cv.best_index_]\n",
    "    print(f'standard deviation: {std}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that the Support Vector Regressor peforms the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg = SVR()\n",
    "\n",
    "svm_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': [0.0001, 0.0005, 0.001, 0.005, 10],\n",
    "    'C': [5, 8, 10, 12, 16, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "452.9095184142313\n",
      "{'kernel': 'linear', 'gamma': 0.0001, 'C': 16}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "svm_cv = RandomizedSearchCV(svm_reg, svm_grid, cv=5, scoring='neg_mean_absolute_error', verbose=4, n_jobs=-1, n_iter=60)\n",
    "\n",
    "svm_cv.fit(X_train_prepared, y_train)\n",
    "\n",
    "print(-svm_cv.best_score_)\n",
    "print(svm_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "The best predictor is Support Vector Regressor (linear kernel, C=16) with a MAE of 452.9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1ffc42b7688ee54d4509547a2cb46af3c49bac4d5c1def4786231871a29c157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
